{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d33ff2fa-192a-4864-ac79-61c786d8f2cd",
   "metadata": {},
   "source": [
    "# 7.1 PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb013a-d23a-405d-88eb-28290aecb3b1",
   "metadata": {},
   "source": [
    "This notebook is an adaptation of the PyTorch Tutorial of Patrick Loeber which you can find [here](https://github.com/python-engineer/pytorchTutorial) (MIT License - Copyright (c) 2020 Patrick Loeber)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718414fa-fd14-49d3-ae3d-97726d7ffb1f",
   "metadata": {},
   "source": [
    "- one of the most popular modern deep learning frameworks (next to Tensorflow, JAX)\n",
    "- [Deep learning with PyTorch Free Online Course](https://www.youtube.com/watch?v=c36lUUr864M&t=8387s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec89cfe-7d35-4097-86d8-270e75fb95f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7432de24-4d80-405c-a63d-5dade646033e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7daa3bb-f8b3-4aaf-8d90-93d09080f11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd95cbd-4b58-4cc5-a813-1b83cc021a03",
   "metadata": {},
   "source": [
    "## Tensor Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56acb965-e71e-48d2-a80b-170360760802",
   "metadata": {},
   "source": [
    "Tensors are generalizations of matrices to the N-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3220b13b-31f8-4738-8b26-e03a20c35806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 9.1983e+36,  6.8934e+28,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.5250e+19,  1.2819e+19,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4965e+03,  1.3473e-32,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.1983e+36,  6.8934e+28,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2, 2, 2, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e30c778-3392-4e54-9ff5-5389543b61cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5477, 0.4624, 0.4226, 0.4258, 0.7716],\n",
      "        [0.8220, 0.7458, 0.8541, 0.5216, 0.4992],\n",
      "        [0.0665, 0.9569, 0.6169, 0.6040, 0.8559]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa760cc-a166-4fd6-a05d-a7605f9a843f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2, 2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d397cb-78fc-4719-afd9-5a41e9c4824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d450ccd3-7280-4a90-8c1c-c2a19628bc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int32\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, dtype=torch.int)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c8d58a-4382-459f-a555-07e2d07d410f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e3aa32d-1d8c-44eb-a54c-513e2e1cc9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5000, 0.1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.5, 0.1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8843caa4-3fb8-4ae4-800e-5b0ef7e7e240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6312, 0.9977],\n",
      "        [0.7299, 0.5425]])\n",
      "tensor([[0.8836, 0.9797],\n",
      "        [0.3575, 0.5241]])\n",
      "tensor([[1.5148, 1.9774],\n",
      "        [1.0874, 1.0666]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "z = x + y\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6e64bd0-c4de-433d-ad04-8b9d00823146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0706, 0.1597, 0.9255],\n",
      "        [0.3883, 0.6203, 0.9053],\n",
      "        [0.6559, 0.5430, 0.9180],\n",
      "        [0.1457, 0.8368, 0.0138],\n",
      "        [0.7126, 0.8969, 0.1990]])\n",
      "tensor([0.0706, 0.3883, 0.6559, 0.1457, 0.7126])\n",
      "0.6202679872512817\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "print(x[:, 0])\n",
    "print(x[1,1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36b091fb-60cc-45d3-8557-524823ba9be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2733, 0.7027, 0.5132, 0.5235],\n",
      "        [0.2758, 0.7580, 0.6494, 0.8495],\n",
      "        [0.7635, 0.4385, 0.4939, 0.8465],\n",
      "        [0.5806, 0.6076, 0.4348, 0.6909]])\n",
      "tensor([0.2733, 0.7027, 0.5132, 0.5235, 0.2758, 0.7580, 0.6494, 0.8495, 0.7635,\n",
      "        0.4385, 0.4939, 0.8465, 0.5806, 0.6076, 0.4348, 0.6909])\n",
      "tensor([[0.2733, 0.7027, 0.5132, 0.5235, 0.2758, 0.7580, 0.6494, 0.8495],\n",
      "        [0.7635, 0.4385, 0.4939, 0.8465, 0.5806, 0.6076, 0.4348, 0.6909]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 4)\n",
    "print(x)\n",
    "y = x.view(16)\n",
    "print(y)\n",
    "y = x.view(-1, 8)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "780c3730-2c84-48a0-9f4c-d9cc6c09e043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(type(a))\n",
    "b = a.numpy()\n",
    "print(type(b))\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# both objects share the same memory location when the tensor is on cpu\n",
    "a += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53e703c7-4795-4159-883e-17dd75cf1758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "print(a)\n",
    "b = torch.from_numpy(a)\n",
    "print(b)\n",
    "a += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43e3681c-d571-408b-8725-f163e9962b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, requires_grad=True) # calculate gradients for this vector in the optimization step\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d7d9f1-7f76-4756-9e51-b66b315b17bd",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b442ef2-8591-442f-a6c5-cfc71e477dc1",
   "metadata": {},
   "source": [
    "Calculating gradients automatically for the optimization. PyTorch will create a computation graph for backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9448628e-6f16-4b6c-9468-04cb946eff36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.0720e-03,  2.4433e+00, -1.4597e+00], requires_grad=True)\n",
      "tensor([2.0021, 4.4433, 0.5403], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b287663-ea93-4bc9-a5a0-90a1e8e6592c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8.0166, 39.4864,  0.5838], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = (y*y*2)\n",
    "# z = z.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ae1aa24-2a52-4109-80da-11f941f73e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
    "z.backward(v) # dz/dx -> chain rule dz/dy * dy/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bd53c80-a475-4f8b-ba6e-ea4af585c5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.0083e-01, 1.7773e+01, 2.1612e-03])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "935b3e42-289b-43f2-b9d7-32b32713ae84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0021, 4.4433, 0.5403])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y = x + 2\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ca6fc08-69ff-498f-bc25-80ad334ce71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(2):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2b416b8-39ee-4fc9-8432-b4d794327753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(2):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97686ec7-03c0-406f-9a00-5c043bad6eb6",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "546d050b-59ef-447f-84ce-2c052f8d5699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    " \n",
    "# forward pass and compute loss\n",
    "y_hat = w * x\n",
    "loss = (y_hat - y)**2\n",
    "print(loss)\n",
    "\n",
    "# backward pass\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "\n",
    "# update weights\n",
    "# next forward and backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a093fa8-2856-4cc3-86a6-f814c900b73c",
   "metadata": {},
   "source": [
    "## Gradient Descent using Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56591d4-2543-4b17-ae2f-606bd6ff282a",
   "metadata": {},
   "source": [
    "Linear Regression: Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9b0ee2f-aaac-4446-9d35-61c65aeb64e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018677\n",
      "epoch 5: w = 1.113, loss = 8.17471600\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698175\n",
      "epoch 15: w = 1.825, loss = 0.31684822\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "Prediction after training: f(5) = 9.612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32) # feature vector\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32) # label vector w. ground truth\n",
    "w = 0.0\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted -y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (w*x-y)**2\n",
    "# dJ/dw = 1/N 2x (w*x-y)\n",
    "def gradient(x, y, y_predicted):\n",
    "    return np.dot(2 * x, y_predicted-y)/len(x)\n",
    "\n",
    "print(f\"Prediction before training: f(5) = {forward(5):.3f}\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    dw = gradient(X, Y, y_pred)\n",
    "    \n",
    "    # update weights\n",
    "    w -= learning_rate * dw\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "772e51d8-cf09-4e64-9fdd-4248cbb838ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018772\n",
      "epoch 5: w = 1.113, loss = 8.17471695\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698116\n",
      "epoch 15: w = 1.825, loss = 0.31684780\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "Prediction after training: f(5) = 9.612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32) # feature vector\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32) # label vector w. ground truth\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted -y)**2).mean()\n",
    "\n",
    "print(f\"Prediction before training: f(5) = {forward(5):.3f}\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    with torch.no_grad(): # exclude from computational graph\n",
    "        w -= learning_rate * w.grad \n",
    "    \n",
    "    # zero gradients\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af832ae-0e4d-45ca-b15b-0bba54f28b6a",
   "metadata": {},
   "source": [
    "## PyTorch Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe14bf6-ad74-4978-b619-5e1be030dc47",
   "metadata": {},
   "source": [
    "1) Design model (input_size, output_size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "   - forward pass: compute prediction\n",
    "   - backward pass: compute gradients\n",
    "   - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cc7ed0b-af73-4966-8098-3cd4294d3326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018772\n",
      "epoch 5: w = 1.113, loss = 8.17471695\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698116\n",
      "epoch 15: w = 1.825, loss = 0.31684780\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "Prediction after training: f(5) = 9.612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32) # feature vector\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32) # label vector w. ground truth\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "\n",
    "\n",
    "print(f\"Prediction before training: f(5) = {forward(5):.3f}\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_epochs = 20\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr=learning_rate) # stochastic gradient descent\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b61efcaf-b5ec-4891-8d14-f9d10d8a8a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "Prediction before training: f(5) = 3.479\n",
      "epoch 1: w = 0.891, loss = 12.75840759\n",
      "epoch 3: w = 1.199, loss = 6.65996790\n",
      "epoch 5: w = 1.421, loss = 3.47654557\n",
      "epoch 7: w = 1.582, loss = 1.81477809\n",
      "epoch 9: w = 1.698, loss = 0.94732493\n",
      "epoch 11: w = 1.782, loss = 0.49450982\n",
      "epoch 13: w = 1.842, loss = 0.25813699\n",
      "epoch 15: w = 1.886, loss = 0.13474920\n",
      "epoch 17: w = 1.918, loss = 0.07033992\n",
      "epoch 19: w = 1.941, loss = 0.03671792\n",
      "Prediction after training: f(5) = 9.747\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32) # feature vector\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32) # label vector w. ground truth\n",
    "\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, bias):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # define layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim, bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "    \n",
    "model = LinearRegression(input_size, output_size, False)\n",
    "\n",
    "print(f\"Prediction before training: f(5) = {model(X_test).item():.3f}\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_epochs = 20\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # stochastic gradient descent\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # prediction = forward pass\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        [w,] = model.parameters()\n",
    "        print(f\"epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after training: f(5) = {model(X_test).item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49889872-2d91-42af-9722-6c2edeaa0f23",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec9886-b81a-4d88-aeb5-f3ed421f2ffa",
   "metadata": {},
   "source": [
    "1) Design model (input_size, output_size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "   - forward pass: compute prediction\n",
    "   - backward pass: compute gradients\n",
    "   - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61095285-3b4e-4337-b433-9fb69d77d57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10, loss = 4376.0596\n",
      "epoch:20, loss = 3262.9531\n",
      "epoch:30, loss = 2458.2808\n",
      "epoch:40, loss = 1875.9185\n",
      "epoch:50, loss = 1454.0054\n",
      "epoch:60, loss = 1148.0383\n",
      "epoch:70, loss = 925.9549\n",
      "epoch:80, loss = 764.6242\n",
      "epoch:90, loss = 647.3370\n",
      "epoch:100, loss = 562.0093\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 0) prepare data\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0], 1)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# 1) model\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# 2) loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # forward pass and loss\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, y)\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"epoch:{epoch+1}, loss = {loss.item():.4f}\")\n",
    "        \n",
    "# plot\n",
    "predicted = model(X).detach().numpy()\n",
    "plt.plot(X_numpy, y_numpy, \"ro\")\n",
    "plt.plot(X_numpy, predicted, \"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816025f3-c171-4cb0-9514-2bfaf8152138",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88111bd6-20d4-417c-9e7d-1164917fd363",
   "metadata": {},
   "source": [
    "1) Design model (input_size, output_size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "   - forward pass: compute prediction\n",
    "   - backward pass: compute gradients\n",
    "   - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df5829fc-3d44-453e-aff3-0d211a8aebe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569 30\n",
      "epoch 10, loss = 0.6096\n",
      "epoch 20, loss = 0.4814\n",
      "epoch 30, loss = 0.4057\n",
      "epoch 40, loss = 0.3559\n",
      "epoch 50, loss = 0.3206\n",
      "epoch 60, loss = 0.2940\n",
      "epoch 70, loss = 0.2733\n",
      "epoch 80, loss = 0.2565\n",
      "epoch 90, loss = 0.2427\n",
      "epoch 100, loss = 0.2309\n",
      "accuracy = 0.9386\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0) prepare data\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# scale\n",
    "sc = StandardScaler() # 0 mean unit variance\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "# 1) model\n",
    "# f = wx + b, sigmoid at the end\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_predicted = torch.sigmoid(self.linear(x))\n",
    "        return y_predicted\n",
    "    \n",
    "model = LogisticRegression(n_features)\n",
    "\n",
    "# 2) loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    # forward pass and loss\n",
    "    y_predicted = model(X_train)\n",
    "    loss = criterion(y_predicted, y_train)\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # updates\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"epoch {epoch+1}, loss = {loss.item():.4f}\")\n",
    "              \n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f\"accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc822bee-5a50-4f19-8808-f0e1f875b41d",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0fa151-dadb-4d11-bceb-07054b73b459",
   "metadata": {},
   "source": [
    "Gradient calculations on whole training dataset is very time-consuming. Better way is to divide samples in so called batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa41b5b-f6be-4f42-b449-671caddee64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b31213f-ecae-4707-bb31-e5a12c349096",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        xy = np.loadtxt(\"../datasets/wine.csv\", delimiter=\",\", dtype=np.float32, skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[:, 1:])\n",
    "        self.y = torch.from_numpy(xy[:, [0]]) # n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbe4eacf-1509-41eb-be84-49ec407f4055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67578d0b-a8ab-42fa-829e-08aefbe5e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2978b5f3-a690-4437-9959-713a6f568f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3880e+01, 5.0400e+00, 2.2300e+00, 2.0000e+01, 8.0000e+01, 9.8000e-01,\n",
      "         3.4000e-01, 4.0000e-01, 6.8000e-01, 4.9000e+00, 5.8000e-01, 1.3300e+00,\n",
      "         4.1500e+02],\n",
      "        [1.1610e+01, 1.3500e+00, 2.7000e+00, 2.0000e+01, 9.4000e+01, 2.7400e+00,\n",
      "         2.9200e+00, 2.9000e-01, 2.4900e+00, 2.6500e+00, 9.6000e-01, 3.2600e+00,\n",
      "         6.8000e+02],\n",
      "        [1.2210e+01, 1.1900e+00, 1.7500e+00, 1.6800e+01, 1.5100e+02, 1.8500e+00,\n",
      "         1.2800e+00, 1.4000e-01, 2.5000e+00, 2.8500e+00, 1.2800e+00, 3.0700e+00,\n",
      "         7.1800e+02],\n",
      "        [1.1030e+01, 1.5100e+00, 2.2000e+00, 2.1500e+01, 8.5000e+01, 2.4600e+00,\n",
      "         2.1700e+00, 5.2000e-01, 2.0100e+00, 1.9000e+00, 1.7100e+00, 2.8700e+00,\n",
      "         4.0700e+02]]) tensor([[3.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.]])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(dataloader)\n",
    "data = dataiter.next()\n",
    "features, labels = data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f590a3da-ac85-4645-b6a4-bc88d8d5fd7c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n",
      "epoch 1/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 45/45, inputs torch.Size([2, 13])\n",
      "epoch 2/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 45/45, inputs torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "n_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        # forward backward, update\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f\"epoch {epoch+1}/{n_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b904bb-f03d-4436-8d87-996789917a78",
   "metadata": {},
   "source": [
    "## Dataset Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421de70-52bd-4af8-bb86-26227d23580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69023c58-4331-46c2-bfdf-3ac8b219f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        # data loading\n",
    "        xy = np.loadtxt(\"../datasets/wine.csv\", delimiter=\",\", dtype=np.float32, skiprows=1)\n",
    "        self.x = xy[:, 1:]\n",
    "        self.y = xy[:, [0]] # n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # dataset[0]\n",
    "        sample = self.x[index], self.y[index]\n",
    "    \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "        \n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples\n",
    "    \n",
    "    \n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "    \n",
    "\n",
    "class MulTransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02e3bb40-9c90-4ee9-b23a-47cfe6d407d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "dataset = WineDataset(transform=ToTensor())\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48cdb8dc-1998-4d58-a5e9-5335a1660024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
      "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
      "        2.1300e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
    "dataset = WineDataset(transform=composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ace5ec-3f03-43ec-93fc-a6f4bf8eebeb",
   "metadata": {},
   "source": [
    "## Softmax & Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5d9c5e2-d90b-4bde-a98d-7a4d1b367206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax numpy: [0.65900114 0.24243297 0.09856589]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "outputs = softmax(x)\n",
    "print(\"Softmax numpy:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19d85185-0094-40df-a139-4f494d45008a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax torch: tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "outputs = torch.softmax(x, dim=0)\n",
    "print(\"Softmax torch:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63916baa-1b9a-416f-902d-5a2b424a5ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1 numpy: 0.3567\n",
      "Loss 2 numpy: 2.3026\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(actual, predicted):\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss # / float(predicted.shape[0])\n",
    "\n",
    "Y = np.array([1, 0, 0]) # one hot encoded\n",
    "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "print(f\"Loss 1 numpy: {l1:.4f}\")\n",
    "print(f\"Loss 2 numpy: {l2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e68f15f0-025b-488f-bebd-a18df05a5239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3877a5c9-9089-422a-88dd-9d1b8e0a3633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1 torch: 0.4170\n",
      "Loss 2 torch: 1.8406\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "Y = torch.tensor([0]) # not one hot encoded\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]]) # n_samples x n_classes = 1x3; logits (softmax is applied within CrossEntropyLoss()\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(f\"Loss 1 torch: {l1.item():.4f}\")\n",
    "print(f\"Loss 2 torch: {l2.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "295cf503-c071-4adc-a5d7-b51a2c1a8a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "_, predictions1 = torch.max(Y_pred_good, 1) # choose highest probability\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(predictions1)\n",
    "print(predictions2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c580e-3126-4adc-9df9-bda8b46c0a5f",
   "metadata": {},
   "source": [
    "Loss in PyTorch allows for multiple examples simultaneously!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ffad4c9-24e7-45b3-ac7a-035935484e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1 torch: 0.3018\n",
      "Loss 2 torch: 1.6242\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "Y = torch.tensor([2, 0, 1]) # not one hot encoded\n",
    "Y_pred_good = torch.tensor([[0.1, 1.0, 2.1], [2.0, 1.0, 0.1], [0.1, 3.0, 0.1]]) # n_samples x n_classes = 3x3; logits (softmax is applied within CrossEntropyLoss()\n",
    "Y_pred_bad = torch.tensor([[2.1, 1.0, 0.1], [0.1, 1.0, 2.1], [0.1, 3.0, 0.1]])\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(f\"Loss 1 torch: {l1.item():.4f}\")\n",
    "print(f\"Loss 2 torch: {l2.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd3211-15cb-434b-8572-0d2a8f9205c0",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c26ff9f-d95d-4bcd-a706-015de2c22027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Option 1 activation functions as modules\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "# option 2 activation function directly in forward pass\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.linear1(x)) # some activation functions only available in functional API, e.g. F.leaky_relu()\n",
    "        out = torch.sigmoid(self.linear2(out))\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce461d-e9aa-4665-b8dd-dab33f8fb7cd",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030ba01-fe80-49f8-b2e1-a20cb18d3a20",
   "metadata": {},
   "source": [
    "### Dataset & DataLoader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8a3782b0-9b78-4368-8136-643683181e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sizes: {'train': 60000, 'val': 10000}\n",
      "Class Names: ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
      "Number of Classes: 10\n",
      "Image Size: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# Device config (GPU support)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Datasets & DataLoaders\n",
    "datasets = {x: torchvision.datasets.FashionMNIST(root=\"../datasets\", train=(x==\"train\"),\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "                  for x in [\"train\", \"val\"]}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in [\"train\", \"val\"]}\n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(datasets[x]) for x in [\"train\", \"val\"]}\n",
    "class_names = datasets[\"train\"].classes\n",
    "n_classes = len(class_names)\n",
    "examples = iter(dataloaders[\"train\"])\n",
    "samples, labels = examples.next()\n",
    "input_size = samples.shape[2] * samples.shape[3] # 784 -> 28x28 images flattened\n",
    "print(f\"Dataset Sizes: {dataset_sizes}\")\n",
    "print(f\"Class Names: {class_names}\")\n",
    "print(f\"Number of Classes: {n_classes}\")\n",
    "print(f\"Image Size: {samples.shape[1:]}\")\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "90bd508f-668d-4f4a-b414-e9745d75f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (batch training)\n",
    "def train_model(model, criterion, optimizer, n_epochs=5, greyscale_to_rgb=False):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for images, labels in dataloaders[phase]:\n",
    "                if greyscale_to_rgb == True:\n",
    "                    images = images.repeat(1, 3, 1, 1).to(device)\n",
    "                else:\n",
    "                    images = images.to(device) # push to GPU if available\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(images)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f\"{phase.capitalize() + ' Phase -> '} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "    print(f\"Best Val Acc: {best_acc:4f}\")\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "14fe72b7-45fc-403e-b353-44fb7938a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 28*28)\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "3e303f70-8fe9-46fe-a73d-8b2f3ad44db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [237]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      9\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [235]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, n_epochs, greyscale_to_rgb)\u001b[0m\n\u001b[1;32m     39\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     40\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 41\u001b[0m         \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# statistics\u001b[39;00m\n\u001b[1;32m     44\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/datascience-bootcamp-7/lib/python3.9/site-packages/torch/optim/optimizer.py:109\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/datascience-bootcamp-7/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/datascience-bootcamp-7/lib/python3.9/site-packages/torch/optim/sgd.py:140\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mis_sparse:\n\u001b[1;32m    138\u001b[0m     has_sparse_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmomentum_buffer\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m state:\n\u001b[1;32m    142\u001b[0m     momentum_buffer_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/datascience-bootcamp-7/lib/python3.9/site-packages/torch/_tensor.py:731\u001b[0m, in \u001b[0;36mTensor.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    726\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPassing a tensor of different shape won\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt change the number of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    727\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterations executed (and might lead to errors or silently give \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    728\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincorrect results).\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mTracerWarning, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m--> 731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    733\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__hash__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 100\n",
    "n_epochs = 15\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, n_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf93db9-d28e-4f39-b12a-67b2626de5c1",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "98afdd4d-862b-4190-98dc-c7bd68cf8a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x -> n, 1, 28, 28\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 12, 12\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 4, 4\n",
    "        x = x.view(-1, 16 * 4 * 4)            # -> n, 256\n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 10\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ccaa8831-7485-4db5-93f5-9307b5b69b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "----------\n",
      "Train Phase ->  Loss: 1.0229 Acc: 0.6210\n",
      "Val Phase ->  Loss: 0.6067 Acc: 0.7741\n",
      "\n",
      "Epoch 2/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.5414 Acc: 0.7984\n",
      "Val Phase ->  Loss: 0.5266 Acc: 0.8032\n",
      "\n",
      "Epoch 3/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.4558 Acc: 0.8330\n",
      "Val Phase ->  Loss: 0.4644 Acc: 0.8343\n",
      "\n",
      "Epoch 4/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.4014 Acc: 0.8524\n",
      "Val Phase ->  Loss: 0.4160 Acc: 0.8458\n",
      "\n",
      "Epoch 5/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3722 Acc: 0.8628\n",
      "Val Phase ->  Loss: 0.3758 Acc: 0.8656\n",
      "\n",
      "Epoch 6/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3448 Acc: 0.8736\n",
      "Val Phase ->  Loss: 0.3782 Acc: 0.8627\n",
      "\n",
      "Epoch 7/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3231 Acc: 0.8819\n",
      "Val Phase ->  Loss: 0.3506 Acc: 0.8699\n",
      "\n",
      "Epoch 8/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3129 Acc: 0.8852\n",
      "Val Phase ->  Loss: 0.3389 Acc: 0.8785\n",
      "\n",
      "Epoch 9/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2990 Acc: 0.8898\n",
      "Val Phase ->  Loss: 0.3450 Acc: 0.8757\n",
      "\n",
      "Epoch 10/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2856 Acc: 0.8946\n",
      "Val Phase ->  Loss: 0.3403 Acc: 0.8777\n",
      "\n",
      "Epoch 11/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2786 Acc: 0.8965\n",
      "Val Phase ->  Loss: 0.3079 Acc: 0.8891\n",
      "\n",
      "Epoch 12/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2720 Acc: 0.8997\n",
      "Val Phase ->  Loss: 0.3228 Acc: 0.8817\n",
      "\n",
      "Epoch 13/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2624 Acc: 0.9017\n",
      "Val Phase ->  Loss: 0.3076 Acc: 0.8910\n",
      "\n",
      "Epoch 14/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2557 Acc: 0.9056\n",
      "Val Phase ->  Loss: 0.3069 Acc: 0.8902\n",
      "\n",
      "Epoch 15/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2492 Acc: 0.9072\n",
      "Val Phase ->  Loss: 0.3058 Acc: 0.8885\n",
      "\n",
      "Training complete in 1m 24s\n",
      "Best Val Acc: 0.891000\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "n_epochs = 15\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21d27f-2a82-4d90-bb15-c3bd780ee9f9",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe62a773-ecc1-40f9-b68d-129b22e7272f",
   "metadata": {},
   "source": [
    "- Super popular nowadays, crucial for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ffca56c4-d234-49c4-a97e-0485ecec03fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3680 Acc: 0.8695\n",
      "Val Phase ->  Loss: 0.3067 Acc: 0.8900\n",
      "\n",
      "Epoch 2/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2405 Acc: 0.9121\n",
      "Val Phase ->  Loss: 0.2544 Acc: 0.9066\n",
      "\n",
      "Epoch 3/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2079 Acc: 0.9240\n",
      "Val Phase ->  Loss: 0.2303 Acc: 0.9161\n",
      "\n",
      "Epoch 4/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.1783 Acc: 0.9335\n",
      "Val Phase ->  Loss: 0.2352 Acc: 0.9176\n",
      "\n",
      "Epoch 5/15\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [238]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      7\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreyscale_to_rgb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [235]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, n_epochs, greyscale_to_rgb)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     39\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 40\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# statistics\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/datascience-bootcamp-7/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/datascience-bootcamp-7/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 100\n",
    "n_epochs = 5\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, n_epochs=n_epochs, greyscale_to_rgb=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# 4. Data Preprocessing & Feature Engineering

Preprocessing is processing raw data prior to ML model building to improve data quality. 

![image](https://user-images.githubusercontent.com/54147355/182630305-f9d3fdfc-5e6c-4efd-a0f6-bbdce68f7ca2.png)

We can broadly categorize different preprocessing actions into 3 catecories:
- Data cleaning (dealing with missing or corrupt data)
- Feature engineering (creating new features out of the original ones)
- Feature selection (reducing the dimensionality of dataset by selecting a subset of features)

In this bootcamp, we cover the most essential preprocessing methods including the following topics:
1. Missing Data Imputation\
1.1. Complete Case Analysis, 
1.2 Mean or Median Imputation
1.3 Frequent Category Imputation
2. Categorical Variable Encoding\
2.1. Label Encoding, 
2.2. Count or frequency Encoding, 
2.3. One Hot Encoding 
3. Outlier Handling\
3.1. Outlier trimming, 
3.2. Outlier Capping
4. Feature Scaling\
4.1 Standardization, 
4.2 Min-Max Scaling
5. Feature selection\
5.1 Dropping Constant Features, 
5.2 Correlation-based Feature Selection

The present repository folder consists of the following items
- 4.1_data_preprocessing_&_feature_engineering.pptx (Powerpoint slides covering the theory part + highlevel codes)
- Regression_dataset_preprocessing.ipynb (Jupyter notebook, including code for preprocessing the dataset "../datasets/regression/raw/regression_50.csv")
- Assignment_classification_preprocessing.ipynb (Jupyter notebook, including hints for preprocessing the dataset "../datasets/classification/raw/classification_25.csv")
- Solution_Classification_preprocessing.ipynb (Jupyter notebook, including solution codes for preprocessing the dataset "../datasets/classification/raw/classification_25.csv")



{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4LQk7OwuGue"
   },
   "source": [
    "# **Baseline Model Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dByMsuzT8Tnw"
   },
   "outputs": [],
   "source": [
    "#importing required libraries for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Import Data balancing libraries\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Import models from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Import evaluation metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5250, 86) (2250, 86) (5250, 1) (2250, 1)\n"
     ]
    }
   ],
   "source": [
    "# Read the training & test datasets from Part1-Preprocessing part\n",
    "\n",
    "x_train=pd.read_csv('x_train.csv')\n",
    "x_test=pd.read_csv('x_test.csv')\n",
    "\n",
    "y_train=pd.read_csv('y_train.csv')\n",
    "y_test=pd.read_csv('y_test.csv')\n",
    "\n",
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Balancing\n",
    "\n",
    "\n",
    "In supervised learning, a common strategy to overcome the class imbalance problem is to resample the original training dataset to decrease the overall level of class imbalance. Resampling is done either by oversampling the minority (positive) class and/or under-sampling the majority (negative) class until the classes are approximately equally represented.\n",
    "\n",
    "All resampling operations are applied to only training datasets. If upsampling is done before splitting the dataset into a train and validation set, then it could end up with the same observation in both datasets. As a result, a machine learning model will be able to perfectly predict the value for those observations when predicting on the validation set, hence inflating the accuracy and recall.\n",
    "\n",
    "A. Under Sampling:\n",
    "\n",
    "    1. Random undersampling --> rus =  RandomUnderSampler()\n",
    "    2. Near Miss --> nm = NearMiss()\n",
    "\n",
    "B. Over Sampling:\n",
    "    \n",
    "    3. Random oversampling  --> ros =  RandomOverSampler()\n",
    "    4. SMOTE (Synthetic Minority Over-Sampling Technique)\n",
    "        sm = SMOTE()\n",
    "        x_train_smote, y_train_smote = sm.fit_sample(x_train, y_train)\n",
    "        x_train_smote.shape,y_train_smote.shape\n",
    "    5. ADASYN (Adaptive Synthetic Sampling) --> adasyn =  ADASYN()\n",
    "\n",
    "C. Hybrid Sampling:\n",
    "\n",
    "    6. SMOTE+ENN --> smtenn =  SMOTEENN()\n",
    "    7. SMOTE+Tomek link --> smtom =  SMOTETomek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original unbalanced dataset shape 5250\n",
      "Resampled balanced dataset shape 8242\n"
     ]
    }
   ],
   "source": [
    "#importing SMOTE to handle class imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "# fit predictor and target variable\n",
    "x_smote, y_smote = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "print('Original unbalanced dataset shape', len(y_train))\n",
    "print('Resampled balanced dataset shape', len(y_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving final balanced files in csv format for future reference (for Part 3)\n",
    "\n",
    "pd.DataFrame(x_smote).to_csv(\"x_smote.csv\", index=None)\n",
    "pd.DataFrame(y_smote).to_csv(\"y_smote.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HD-O64CJaWG"
   },
   "source": [
    "### 1. **Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xltV-JKlH76A",
    "outputId": "7c475b05-d52e-43e5-d06b-98ae5ff16b6b"
   },
   "outputs": [],
   "source": [
    "# Importing the Logistic Regression Model\n",
    "logmodel = LogisticRegression(random_state=1)\n",
    "logmodel.fit(x_smote,y_smote)\n",
    "\n",
    "# predicting the y test observations\n",
    "y_pred = logmodel.predict(x_test)\n",
    "y_train_pred = logmodel.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUYBmWtyNfUs",
    "outputId": "514389aa-365a-4c20-fc73-f3ab00cdae36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train Accuracy  Test Accuracy  Precision  Recall  \\\n",
       "0  Logistic Regression           0.703           0.77      0.569   0.505   \n",
       "\n",
       "   F1 Score    ROC  \n",
       "0     0.535  0.684  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all scores for Logistic Regression\n",
    "log_acctr = round(accuracy_score(y_train_pred,y_smote), 3)\n",
    "log_acc = round(accuracy_score(y_pred,y_test), 3)\n",
    "log_prec = round(precision_score(y_pred,y_test), 3)\n",
    "log_rec = round(recall_score(y_pred,y_test), 3)\n",
    "log_f1 = round(f1_score(y_pred,y_test), 3)\n",
    "log_roc = round(roc_auc_score(y_pred,y_test), 3)\n",
    "\n",
    "results = pd.DataFrame([['Logistic Regression', log_acctr, log_acc, log_prec, log_rec, log_f1, log_roc]],\n",
    "               columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85      1726\n",
      "           1       0.51      0.57      0.54       524\n",
      "\n",
      "    accuracy                           0.77      2250\n",
      "   macro avg       0.68      0.70      0.69      2250\n",
      "weighted avg       0.78      0.77      0.77      2250\n",
      "\n",
      "[[1434  292]\n",
      " [ 226  298]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HD-O64CJaWG"
   },
   "source": [
    "### 2. **Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xltV-JKlH76A",
    "outputId": "7c475b05-d52e-43e5-d06b-98ae5ff16b6b"
   },
   "outputs": [],
   "source": [
    "# Importing the Naive Bayes Model\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_smote,y_smote)\n",
    "\n",
    "# predicting the y test observations\n",
    "y_pred = nb.predict(x_test)\n",
    "y_train_pred = nb.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUYBmWtyNfUs",
    "outputId": "514389aa-365a-4c20-fc73-f3ab00cdae36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Train Accuracy  Test Accuracy  Precision  Recall  F1 Score  \\\n",
       "0  Naive Bayes           0.542          0.781      0.105   0.696     0.182   \n",
       "\n",
       "    ROC  \n",
       "0  0.74  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all scores for Naive Bayes Model\n",
    "nb_acctr = round(accuracy_score(y_train_pred,y_smote), 3)\n",
    "nb_acc = round(accuracy_score(y_pred,y_test), 3)\n",
    "nb_prec = round(precision_score(y_pred,y_test), 3)\n",
    "nb_rec = round(recall_score(y_pred,y_test), 3)\n",
    "nb_f1 = round(f1_score(y_pred,y_test), 3)\n",
    "nb_roc = round(roc_auc_score(y_pred,y_test), 3)\n",
    "\n",
    "results = pd.DataFrame([['Naive Bayes', nb_acctr, nb_acc, nb_prec, nb_rec, nb_f1, nb_roc]],\n",
    "               columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87      1726\n",
      "           1       0.70      0.10      0.18       524\n",
      "\n",
      "    accuracy                           0.78      2250\n",
      "   macro avg       0.74      0.55      0.53      2250\n",
      "weighted avg       0.76      0.78      0.71      2250\n",
      "\n",
      "[[1702   24]\n",
      " [ 469   55]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HD-O64CJaWG"
   },
   "source": [
    "### 3. **KNN classifier algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xltV-JKlH76A",
    "outputId": "7c475b05-d52e-43e5-d06b-98ae5ff16b6b"
   },
   "outputs": [],
   "source": [
    "# Importing the KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_smote,y_smote)\n",
    "\n",
    "# predicting the y test observations\n",
    "y_pred = knn.predict(x_test)\n",
    "y_train_pred = knn.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUYBmWtyNfUs",
    "outputId": "514389aa-365a-4c20-fc73-f3ab00cdae36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN classifier</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Train Accuracy  Test Accuracy  Precision  Recall  F1 Score  \\\n",
       "0  KNN classifier           0.866          0.659      0.605   0.361     0.453   \n",
       "\n",
       "     ROC  \n",
       "0  0.605  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all scores for KNN classifier\n",
    "knn_acctr = round(accuracy_score(y_train_pred,y_smote), 3)\n",
    "knn_acc = round(accuracy_score(y_pred,y_test), 3)\n",
    "knn_prec = round(precision_score(y_pred,y_test), 3)\n",
    "knn_rec = round(recall_score(y_pred,y_test), 3)\n",
    "knn_f1 = round(f1_score(y_pred,y_test), 3)\n",
    "knn_roc = round(roc_auc_score(y_pred,y_test), 3)\n",
    "\n",
    "results = pd.DataFrame([['KNN classifier', knn_acctr, knn_acc, knn_prec, knn_rec, knn_f1, knn_roc]],\n",
    "               columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.68      0.75      1726\n",
      "           1       0.36      0.60      0.45       524\n",
      "\n",
      "    accuracy                           0.66      2250\n",
      "   macro avg       0.61      0.64      0.60      2250\n",
      "weighted avg       0.74      0.66      0.68      2250\n",
      "\n",
      "[[1166  560]\n",
      " [ 207  317]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1aTiZqyteC3"
   },
   "source": [
    "### 4. **Decision Tree Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFp8TGTFWCcN",
    "outputId": "0b504262-6853-4975-84f9-116768f234f7"
   },
   "outputs": [],
   "source": [
    "#fitting data into Decision Tree Classifier\n",
    "dtc = DecisionTreeClassifier(random_state=1)\n",
    "dtc.fit(x_smote,y_smote)\n",
    "\n",
    "# predicting the y test observations\n",
    "y_pred = dtc.predict(x_test)\n",
    "y_train_pred = dtc.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Trees</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Train Accuracy  Test Accuracy  Precision  Recall  F1 Score  \\\n",
       "0  Decision Trees             1.0          0.692      0.468   0.372     0.415   \n",
       "\n",
       "     ROC  \n",
       "0  0.599  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all scores for Decision Tree Classifier\n",
    "dtc_acctr = round(accuracy_score(y_train_pred,y_smote), 3)\n",
    "dtc_acc = round(accuracy_score(y_pred,y_test), 3)\n",
    "dtc_prec = round(precision_score(y_pred,y_test), 3)\n",
    "dtc_rec = round(recall_score(y_pred,y_test), 3)\n",
    "dtc_f1 = round(f1_score(y_pred,y_test), 3)\n",
    "dtc_roc = round(roc_auc_score(y_pred,y_test), 3)\n",
    "\n",
    "results = pd.DataFrame([['Decision Trees', dtc_acctr, dtc_acc, dtc_prec, dtc_rec, dtc_f1, dtc_roc]],\n",
    "               columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79      1726\n",
      "           1       0.37      0.47      0.41       524\n",
      "\n",
      "    accuracy                           0.69      2250\n",
      "   macro avg       0.60      0.61      0.60      2250\n",
      "weighted avg       0.72      0.69      0.70      2250\n",
      "\n",
      "[[1313  413]\n",
      " [ 279  245]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oQB1e2AuWw4"
   },
   "source": [
    "### 5. **Random Forest Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFp8TGTFWCcN",
    "outputId": "0b504262-6853-4975-84f9-116768f234f7"
   },
   "outputs": [],
   "source": [
    "#fitting data into Random Forest Classifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_smote,y_smote)\n",
    "\n",
    "# predicting the y test observations\n",
    "y_pred = rfc.predict(x_test)\n",
    "y_train_pred = rfc.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Train Accuracy  Test Accuracy  Precision  Recall  F1 Score  \\\n",
       "0  Random Forest             1.0          0.796      0.454   0.579     0.509   \n",
       "\n",
       "     ROC  \n",
       "0  0.712  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all scores for Random Forest Classifier\n",
    "rfc_acctr = round(accuracy_score(y_train_pred,y_smote), 3)\n",
    "rfc_acc = round(accuracy_score(y_pred,y_test), 3)\n",
    "rfc_prec = round(precision_score(y_pred,y_test), 3)\n",
    "rfc_rec = round(recall_score(y_pred,y_test), 3)\n",
    "rfc_f1 = round(f1_score(y_pred,y_test), 3)\n",
    "rfc_roc = round(roc_auc_score(y_pred,y_test), 3)\n",
    "\n",
    "results = pd.DataFrame([['Random Forest', rfc_acctr, rfc_acc, rfc_prec, rfc_rec, rfc_f1, rfc_roc]],\n",
    "               columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      1726\n",
      "           1       0.58      0.45      0.51       524\n",
      "\n",
      "    accuracy                           0.80      2250\n",
      "   macro avg       0.71      0.68      0.69      2250\n",
      "weighted avg       0.78      0.80      0.79      2250\n",
      "\n",
      "[[1553  173]\n",
      " [ 286  238]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f-ashA1uerB"
   },
   "source": [
    "### 6.  **Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ut6-p05v3Jje",
    "outputId": "5347d8a5-606a-41e6-e042-370fee30787a"
   },
   "outputs": [],
   "source": [
    "#fitting data into Gradient Boosting Classifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(x_smote,y_smote)\n",
    "\n",
    "# predicting the y test observations\n",
    "y_pred = gbc.predict(x_test)\n",
    "y_train_pred = gbc.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9vGklUI3Jds",
    "outputId": "0d2e228c-f44b-44f0-b9bf-c52f520ea15c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Train Accuracy  Test Accuracy  Precision  Recall  \\\n",
       "0  Gradient Boosting           0.834          0.793      0.435   0.573   \n",
       "\n",
       "   F1 Score    ROC  \n",
       "0     0.495  0.707  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all scores for Logistic Regression\n",
    "gbc_acctr = round(accuracy_score(y_train_pred,y_smote), 3)\n",
    "gbc_acc = round(accuracy_score(y_pred,y_test), 3)\n",
    "gbc_prec = round(precision_score(y_pred,y_test), 3)\n",
    "gbc_rec = round(recall_score(y_pred,y_test), 3)\n",
    "gbc_f1 = round(f1_score(y_pred,y_test), 3)\n",
    "gbc_roc = round(roc_auc_score(y_pred,y_test), 3)\n",
    "\n",
    "results = pd.DataFrame([['Gradient Boosting', gbc_acctr, gbc_acc, gbc_prec, gbc_rec, gbc_f1, gbc_roc]],\n",
    "               columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      1726\n",
      "           1       0.57      0.44      0.49       524\n",
      "\n",
      "    accuracy                           0.79      2250\n",
      "   macro avg       0.71      0.67      0.68      2250\n",
      "weighted avg       0.78      0.79      0.78      2250\n",
      "\n",
      "[[1556  170]\n",
      " [ 296  228]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVtuI5Ep5rD2"
   },
   "source": [
    "### 7. **XG Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5MR0R5br5VVC",
    "outputId": "94c496f4-210b-476b-a558-d07ed4962707"
   },
   "outputs": [],
   "source": [
    "#fitting data into XG Boosting Classifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_smote,y_smote)\n",
    "\n",
    "# predicting the y test observations\n",
    "y_pred = xgb.predict(x_test)\n",
    "y_train_pred = xgb.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sib751ga5VPH",
    "outputId": "992a7ea7-5824-4aab-8396-ead98b9d1f01"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XG Boosting</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Train Accuracy  Test Accuracy  Precision  Recall  F1 Score  \\\n",
       "0  XG Boosting           0.987          0.791      0.389   0.576     0.465   \n",
       "\n",
       "     ROC  \n",
       "0  0.704  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all scores for XG Boosting Classifier\n",
    "xgb_acctr = round(accuracy_score(y_train_pred,y_smote), 3)\n",
    "xgb_acc = round(accuracy_score(y_pred,y_test), 3)\n",
    "xgb_prec = round(precision_score(y_pred,y_test), 3)\n",
    "xgb_rec = round(recall_score(y_pred,y_test), 3)\n",
    "xgb_f1 = round(f1_score(y_pred,y_test), 3)\n",
    "xgb_roc = round(roc_auc_score(y_pred,y_test), 3)\n",
    "\n",
    "results = pd.DataFrame([['XG Boosting', xgb_acctr, xgb_acc, xgb_prec, xgb_rec, xgb_f1, xgb_roc]],\n",
    "               columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      1726\n",
      "           1       0.58      0.39      0.46       524\n",
      "\n",
      "    accuracy                           0.79      2250\n",
      "   macro avg       0.70      0.65      0.67      2250\n",
      "weighted avg       0.77      0.79      0.78      2250\n",
      "\n",
      "[[1576  150]\n",
      " [ 320  204]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVtuI5Ep5rD2"
   },
   "source": [
    "### 8. **ADA Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5MR0R5br5VVC",
    "outputId": "94c496f4-210b-476b-a558-d07ed4962707"
   },
   "outputs": [],
   "source": [
    "#fitting data into Ada Boosting Classifier\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(x_smote,y_smote)\n",
    "\n",
    "# predicting the y test observations\n",
    "y_pred = ada.predict(x_test)\n",
    "y_train_pred = ada.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sib751ga5VPH",
    "outputId": "992a7ea7-5824-4aab-8396-ead98b9d1f01"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADA Boosting</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Train Accuracy  Test Accuracy  Precision  Recall  F1 Score  \\\n",
       "0  ADA Boosting           0.781          0.764      0.475   0.492     0.483   \n",
       "\n",
       "     ROC  \n",
       "0  0.667  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all scores for Ada Boosting Classifier\n",
    "ada_acctr = round(accuracy_score(y_train_pred,y_smote), 3)\n",
    "ada_acc = round(accuracy_score(y_pred,y_test), 3)\n",
    "ada_prec = round(precision_score(y_pred,y_test), 3)\n",
    "ada_rec = round(recall_score(y_pred,y_test), 3)\n",
    "ada_f1 = round(f1_score(y_pred,y_test), 3)\n",
    "ada_roc = round(roc_auc_score(y_pred,y_test), 3)\n",
    "\n",
    "results = pd.DataFrame([['ADA Boosting', ada_acctr, ada_acc, ada_prec, ada_rec, ada_f1, ada_roc]],\n",
    "               columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85      1726\n",
      "           1       0.49      0.48      0.48       524\n",
      "\n",
      "    accuracy                           0.76      2250\n",
      "   macro avg       0.67      0.66      0.67      2250\n",
      "weighted avg       0.76      0.76      0.76      2250\n",
      "\n",
      "[[1469  257]\n",
      " [ 275  249]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVtuI5Ep5rD2"
   },
   "source": [
    "### 9. **Bagging Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5MR0R5br5VVC",
    "outputId": "94c496f4-210b-476b-a558-d07ed4962707"
   },
   "outputs": [],
   "source": [
    "#fitting data into Bagging Classifier\n",
    "bag = BaggingClassifier()\n",
    "bag.fit(x_smote,y_smote)\n",
    "\n",
    "# predicting the y test observations\n",
    "y_pred = bag.predict(x_test)\n",
    "y_train_pred = bag.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sib751ga5VPH",
    "outputId": "992a7ea7-5824-4aab-8396-ead98b9d1f01"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Train Accuracy  Test Accuracy  Precision  Recall  \\\n",
       "0  Bagging Classifier           0.993          0.776      0.422   0.525   \n",
       "\n",
       "   F1 Score   ROC  \n",
       "0     0.468  0.68  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all scores for Bagging Classifier\n",
    "bag_acctr = round(accuracy_score(y_train_pred,y_smote), 3)\n",
    "bag_acc = round(accuracy_score(y_pred,y_test), 3)\n",
    "bag_prec = round(precision_score(y_pred,y_test), 3)\n",
    "bag_rec = round(recall_score(y_pred,y_test), 3)\n",
    "bag_f1 = round(f1_score(y_pred,y_test), 3)\n",
    "bag_roc = round(roc_auc_score(y_pred,y_test), 3)\n",
    "\n",
    "results = pd.DataFrame([['Bagging Classifier', bag_acctr, bag_acc, bag_prec, bag_rec, bag_f1, bag_roc]],\n",
    "               columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86      1726\n",
      "           1       0.52      0.42      0.47       524\n",
      "\n",
      "    accuracy                           0.78      2250\n",
      "   macro avg       0.68      0.65      0.66      2250\n",
      "weighted avg       0.76      0.78      0.77      2250\n",
      "\n",
      "[[1526  200]\n",
      " [ 303  221]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjzgCVofJAw2"
   },
   "source": [
    "### **Baseline Model Comparision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "hE3oJdoHI_FC"
   },
   "outputs": [],
   "source": [
    "all_classifiers = ['Logistic Regression', 'KNN Classifier', 'Naive Bayes', 'Decision Tree', 'Random Forest',\n",
    "                  'Gradient Boosting', 'XG Boosting', 'Ada Boosting', 'Bagging algorithm']\n",
    "\n",
    "all_train_accuracy =  [log_acctr, knn_acctr, nb_acctr, dtc_acctr, rfc_acctr, gbc_acctr, xgb_acctr, ada_acctr, bag_acctr]\n",
    "all_test_accuracy =   [log_acc, knn_acc, nb_acc, dtc_acc, rfc_acc, gbc_acc, xgb_acc, ada_acc, bag_acc]\n",
    "all_precision_score = [log_prec, knn_prec, nb_prec, dtc_prec, rfc_prec, gbc_prec, xgb_prec, ada_prec, bag_prec]\n",
    "all_recall_score =    [log_rec, knn_rec, nb_rec, dtc_rec, rfc_rec, gbc_rec, xgb_rec, ada_rec, bag_rec]\n",
    "all_f1_score =        [log_f1, knn_f1, nb_f1, dtc_f1, rfc_f1, gbc_f1, xgb_f1, ada_f1, bag_f1]\n",
    "all_roc_score =       [log_roc, knn_roc, nb_roc, dtc_roc, rfc_roc, gbc_roc, xgb_roc, ada_roc, bag_roc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Mg2R56a-JVUY",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XG Boosting</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bagging algorithm</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier  Train Accuracy  Test Accuracy  Precision  Recall  \\\n",
       "0  Logistic Regression           0.703          0.770      0.569   0.505   \n",
       "1       KNN Classifier           0.866          0.659      0.605   0.361   \n",
       "2          Naive Bayes           0.542          0.781      0.105   0.696   \n",
       "3        Decision Tree           1.000          0.692      0.468   0.372   \n",
       "4        Random Forest           1.000          0.796      0.454   0.579   \n",
       "5    Gradient Boosting           0.834          0.793      0.435   0.573   \n",
       "6          XG Boosting           0.987          0.791      0.389   0.576   \n",
       "7         Ada Boosting           0.781          0.764      0.475   0.492   \n",
       "8    Bagging algorithm           0.993          0.776      0.422   0.525   \n",
       "\n",
       "   F1 Score    AUC  \n",
       "0     0.535  0.684  \n",
       "1     0.453  0.605  \n",
       "2     0.182  0.740  \n",
       "3     0.415  0.599  \n",
       "4     0.509  0.712  \n",
       "5     0.495  0.707  \n",
       "6     0.465  0.704  \n",
       "7     0.483  0.667  \n",
       "8     0.468  0.680  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_df = pd.DataFrame({'Classifier':all_classifiers, 'Train Accuracy': all_train_accuracy, 'Test Accuracy': all_test_accuracy, 'Precision': all_precision_score, 'Recall': all_recall_score, 'F1 Score': all_f1_score , 'AUC': all_roc_score})\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion from Baseline models\n",
    "\n",
    "1. From all baseline model, XG Boosting classifier shows better test accuracy and F1 score and AUC.\n",
    "2. Ensemble models shows better performance compated to base models (except for Logistic regression model)\n",
    "3. Train accuracy - There is huge difference between Train and Test Accuracy in tree based models which shows OverFitting\n",
    "\n",
    "We can try in the next part, Cross validation and Hyperparameter tuning techniques to reduce chances of overfitting and also increases performance of model."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Credit Card Default Prediction - Amol.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

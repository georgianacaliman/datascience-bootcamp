{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d86cf74-7cf9-4ea9-bc5d-159e35a16513",
   "metadata": {},
   "source": [
    "## <ins>Data Science Bootcamp - 3th Day- Statistics and ML</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17f39c02-640f-4566-b9f3-781798007d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06522d70-c852-4524-9a93-f19a12e69bac",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83a0740-24f5-4271-844c-e9cfa85aa5b2",
   "metadata": {},
   "source": [
    "# Data types\n",
    "A: Consider the following data and figure out what category of data they are.<br>\n",
    "nominal, ordinal, discrete, continous\n",
    "\n",
    "What is your ethnicity?\n",
    "- Central Asian\n",
    "- Indonesian\n",
    "- West Asian\n",
    "- Japanese\n",
    "- Indian\n",
    "\n",
    "B: The revenue from sales of a company:\n",
    "- $2.8b\n",
    "\n",
    "C: The number of sales of a company:\n",
    "- Product A: 1753\n",
    "- Product B: 104357\n",
    "- Product C: 3\n",
    "\n",
    "D: Grades in school:\n",
    "- 1\n",
    "- 2\n",
    "- 3\n",
    "- 4\n",
    "- 5\n",
    "- 6\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74fb109-540b-4007-9224-37321ba62fe5",
   "metadata": {},
   "source": [
    "- A:\n",
    "- B:\n",
    "- C:\n",
    "- D:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca206fa-07bd-4db6-b518-0a571200b268",
   "metadata": {},
   "source": [
    "# Probabilities\n",
    "What of the following are probailites?\n",
    "- A: P(X) = -0.1\n",
    "- B: P(X) = 1.1\n",
    "- C: P(X) = 1.0\n",
    "- D: P(X) = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbba5f0-d20e-4bd4-bd60-e29cca89d3c5",
   "metadata": {},
   "source": [
    "# Confidence intervall:\n",
    "We want to calculate the confidence intervall of a given data set.<br> The formula for the CI is given by:<br>\n",
    "$\\bar{X}$ is the mean of data set.<br>\n",
    "$u$  is the quantile value.<br>\n",
    "$\\sigma$ is the standartdeviation.<br>\n",
    "$n$ is the number of oberservations.<br>\n",
    "$[upper, lower] = \\bar{X}\\pm u\\cdot\\frac{\\sigma}{\\sqrt{n}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bacba79b-9418-4dd7-9812-c8baab64df24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "data = [45, 55, 67, 45, 68, 79, 98, 87, 84, 82] #given dataset\n",
    "n = len(data)\n",
    "#uncomment the next lime and caculate the mean the the dataset\n",
    "#x = sum(None)/len(None) \n",
    "print(None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4adadc3-9efe-48cc-9e44-aa341b43962d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.23948955160796\n"
     ]
    }
   ],
   "source": [
    "sigma = np.std(data) #calculates the standartdeviation of the dataset\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e11bd-5ac5-47cd-b342-2dab5076915b",
   "metadata": {},
   "source": [
    "From the quantile table we get the u-value of 2.821."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb34377c-d730-4ab0-8542-d24281324758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None\n"
     ]
    }
   ],
   "source": [
    "u = 2.821\n",
    "#write here the formula for the upper and lower bound of the confidence intervall\n",
    "#note the root of a variable is math.sqrt(x)\n",
    "upper = None\n",
    "lower = None\n",
    "print(lower, upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32039ff1-82bb-48a7-9c2e-5d24be3a179a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Choose which kind of ML might the most fitting for the problem:\n",
    "- Predict the future returns of a company.\n",
    "- Data, in which we want to find commonalities, group them together into categories to better advertise to them.\n",
    "- We want to train a robot to do complex maneuvers, but we dont have a lot of data to train the robot on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a66f594-0349-4412-a1fb-9000d1d73080",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "In order to get used to the simplest form of ML, linear regression. We will use a randomly created data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ff5ee35-7dac-4c4f-b6e5-3d0efe5b28ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data creating, no need to understand this\n",
    "np.random.seed(42)\n",
    "#Randomly creates data\n",
    "n_samples, n_features = 200, 50\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "true_coef = 3 * np.random.randn(n_features)\n",
    "# Threshold coefficients to render them non-negative\n",
    "true_coef[true_coef < 0] = 0\n",
    "y = np.dot(X, true_coef)\n",
    "\n",
    "# Add some noise\n",
    "y += 5 * np.random.normal(size=(n_samples,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895467b7-a3d2-4fa4-82be-c5e1b0326395",
   "metadata": {},
   "source": [
    "In order to avoid over- or underfitting we now split the data X and y into two groups. One for training the model and one for vaidating the finished modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3ab709a-cb61-4e3f-9a2b-7b1a22c47c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#uncomment the line below and change the \"Nones\" below to split the data into two set, note the dataset are X and y\n",
    "#X_train, X_test, y_train, y_test = train_test_split(None, None, test_size=0.5) #split the dataset into two, by half/0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "901cb1e1-71c7-4115-a79c-af41b4f73f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg_nnls = LinearRegression(positive=True)\n",
    "#uncomment the next lines and add the above created training dataset to the fit. hint: replace the nones in the next line\n",
    "#y_pred_nnls = reg_nnls.fit(None, None).predict(X_test)\n",
    "#r2_score_nnls = r2_score(y_test, y_pred_nnls)#gets the R^2 of the modell\n",
    "#print(\"NNLS R2 score\", r2_score_nnls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d169865-6a9d-4653-9a3e-819601848a10",
   "metadata": {},
   "source": [
    " Using the NNLS loss-function, we the $R^2$ of the model.<br>\n",
    " $R^2$ is the measesure of how much variance of the model is explained by the model. Generally the higher the better. Our 0.82 is fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cf2f92-d37b-4728-b3aa-4e36cd1dfbf6",
   "metadata": {},
   "source": [
    "Lets use a different Loss-function to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe05a41-4eb9-44c1-88db-4a9c49560d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment the lines below\n",
    "#reg_ols = LinearRegression()\n",
    "#y_pred_ols = reg_ols.fit(X_train, y_train).predict(X_test)\n",
    "#r2_score_ols = r2_score(y_test, y_pred_ols)\n",
    "#print(\"OLS R2 score\", r2_score_ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db15e76-e285-481d-8c11-0677aee3c35f",
   "metadata": {},
   "source": [
    "The OLS loss-function gets us a worse $R^2$, but still a resonable fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b97871f-fc3c-4925-8969-23f9ec8cbf9e",
   "metadata": {},
   "source": [
    "Next we plot the data and regression line to see, how it fits. Uncomment the next cell by removing the \"\"\" at the start and end of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61f4611b-5992-4d33-94a8-adcb720b99f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fig, ax = plt.subplots()\\nax.plot(reg_ols.coef_, reg_nnls.coef_, linewidth=0, marker=\".\")\\n\\nlow_x, high_x = ax.get_xlim()\\nlow_y, high_y = ax.get_ylim()\\nlow = max(low_x, low_y)\\nhigh = min(high_x, high_y)\\nax.plot([low, high], [low, high], ls=\"--\", c=\".3\", alpha=0.5)\\nax.set_xlabel(\"OLS regression coefficients\", fontweight=\"bold\")\\nax.set_ylabel(\"NNLS regression coefficients\", fontweight=\"bold\")'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"fig, ax = plt.subplots()\n",
    "ax.plot(reg_ols.coef_, reg_nnls.coef_, linewidth=0, marker=\".\")\n",
    "\n",
    "low_x, high_x = ax.get_xlim()\n",
    "low_y, high_y = ax.get_ylim()\n",
    "low = max(low_x, low_y)\n",
    "high = min(high_x, high_y)\n",
    "ax.plot([low, high], [low, high], ls=\"--\", c=\".3\", alpha=0.5)\n",
    "ax.set_xlabel(\"OLS regression coefficients\", fontweight=\"bold\")\n",
    "ax.set_ylabel(\"NNLS regression coefficients\", fontweight=\"bold\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1af34-1399-4ba2-a92a-e0979951c5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025b4ebd-fc5e-43c4-9879-7286aebe6ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
